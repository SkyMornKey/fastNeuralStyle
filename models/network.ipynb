{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision as tv\n",
    "from ipynb.fs.full.module import BasicModule\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loss net (vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LossNet(BasicModule):\n",
    "    def __init__(self, requires_grad=False):\n",
    "        super(lossNet, self).__init__()\n",
    "        features = list(tv.models.vgg16(pretrained=True).features)[:23]\n",
    "        self.features = t.nn.ModuleList(features).eval()\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        results = []\n",
    "\n",
    "        # use outputs of relu1_2, relu2_2, relu3_3, relu4_3 as loss\n",
    "        for index, model in enumerate(self.features):\n",
    "            x = model(x)\n",
    "            if index in {3, 8, 15, 22}:\n",
    "                results.append(x)\n",
    "        loss_name = namedtuple(\"vggOutputs\",\n",
    "                               ['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3'])\n",
    "\n",
    "        return loss_name(*results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class residual2d(BasicModule):\n",
    "    def __init__(self, channels):\n",
    "        super(residual2d, self).__init__()\n",
    "        \n",
    "        self.model = t.nn.Sequential(\n",
    "            t.nn.Conv2d(\n",
    "                in_channels=channels,\n",
    "                out_channels=channels,\n",
    "                kernel_size=3,\n",
    "                padding=1),\n",
    "            t.nn.BatchNorm2d(num_features=128),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Conv2d(\n",
    "                in_channels=channels,\n",
    "                out_channels=channels,\n",
    "                kernel_size=3,\n",
    "                padding=1),\n",
    "            t.nn.BatchNorm2d(num_features=128))\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.model(x)\n",
    "\n",
    "        return result + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class TransformNet(BasicModule):\n",
    "    def __init__(self):\n",
    "        super(transformNet, self).__init__()\n",
    "        self.model_name = 'TransformNet'\n",
    "\n",
    "        # convolutional layers\n",
    "        self.convLayers = t.nn.Sequential(\n",
    "            t.nn.Conv2d(\n",
    "                in_channels=3, out_channels=32, kernel_size=9, padding=4),\n",
    "            t.nn.BatchNorm2d(num_features=32),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1),\n",
    "            t.nn.BatchNorm2d(num_features=64),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1),\n",
    "            t.nn.BatchNorm2d(num_features=128),\n",
    "            t.nn.ReLU())\n",
    "\n",
    "        # residual layers\n",
    "        self.resLayers = t.nn.Sequential(\n",
    "            residual2d(128), residual2d(128), residual2d(128), residual2d(128),\n",
    "            residual2d(128))\n",
    "\n",
    "        # deconv layers\n",
    "        self.deconvLayers = t.nn.Sequential(\n",
    "            t.nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1),\n",
    "            t.nn.BatchNorm2d(num_features=64),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.ConvTranspose2d(\n",
    "                in_channels=64,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1),\n",
    "            t.nn.BatchNorm2d(num_features=32),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.ConvTranspose2d(\n",
    "                in_channels=32, out_channels=3, kernel_size=9, padding=4),\n",
    "            t.nn.BatchNorm2d(num_features=3),\n",
    "            t.nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convLayers(x)\n",
    "        x = self.resLayers(x)\n",
    "        x = self.deconvLayers(x)\n",
    "\n",
    "        return x * 127.5 + 127.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
